%% 
%% Copyright 2019-2024 Elsevier Ltd
%% 
%% This file is part of the 'CAS Bundle'.
%% --------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.3c of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.3c or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'CAS Bundle' is
%% given in the file `manifest.txt'.
%% 
%% Template article for cas-dc documentclass for 
%% double column output.

\documentclass[a4paper,fleqn]{cas-dc}

% If the frontmatter runs over more than one page
% use the longmktitle option.

%\documentclass[a4paper,fleqn,longmktitle]{cas-dc}

% \usepackage[numbers]{natbib}
\usepackage[authoryear]{natbib}
% \usepackage[authoryear,longnamesfirst]{natbib}

\usepackage{tabularray}
\usepackage{booktabs}
\usepackage[inter-unit-product =\cdot]{siunitx}
\usepackage{stfloats}
\graphicspath{ {./img/} }
%%%Author macros
\def\tsc#1{\csdef{#1}{\textsc{\lowercase{#1}}\xspace}}
\tsc{WGM}
\tsc{QE}
%%%

% Uncomment and use as if needed
%\newtheorem{theorem}{Theorem}
%\newtheorem{lemma}[theorem]{Lemma}
%\newdefinition{rmk}{Remark}
%\newproof{pf}{Proof}
%\newproof{pot}{Proof of Theorem \ref{thm}}

\begin{document}
\let\WriteBookmarks\relax
\def\floatpagepagefraction{1}
\def\textpagefraction{.001}

% Short title
\shorttitle{Data-Driven Modelling of Cyclic Voltammetry in Upcycled Carbon Supercapacitors}    

% Short author
\shortauthors{M. A. Sandoval and K. Jayathunge}  

% Main title of the paper
\title [mode = title]{Performance of upcycled tyre-derived carbon in ethaline-glycol ionic electrolytes for sustainable supercapacitors: modelling cyclic voltammetry using standard and machine-learning methods.}  

% Title footnote mark
% eg: \tnotemark[1]
% \tnotemark[1] 

% Title footnote 1.
% eg: \tnotetext[1]{Title footnote text}
% \tnotetext[1]{} 

% First author
%
% Options: Use if required
\author[1]{Maria A. Sandoval-Riofrio}[
  orcid=0000-0003-0680-4539
]
% Corresponding author indication
\cormark[1]
% Footnote of the first author
\fnmark[1]
% Email id of the first author
\ead{msandoval2@bournemouth.ac.uk}
% URL of the first author
\ead[url]{https://www.linkedin.com/in/maria-a-sandoval/}


% Credit authorship
% eg: \credit{Conceptualization of this study, Methodology, Software}
\credit{Conceptualization of study, physical experiments, analysis}


\author[1]{Kavisha Jayathunge}[
  orcid=0009-0006-5162-5731
]

% Footnote of the second author
\fnmark[2]

% Email id of the second author
\ead{kjayathunge@bournemouth.ac.uk}

% URL of the second author
\ead[url]{https://staffprofiles.bournemouth.ac.uk/display/kjayathunge}

% Credit authorship
\credit{Data processing, Machine learning modelling, analysis}

% Address/affiliation
\affiliation[1]{organization={Bournemouth University},
            addressline={Talbot Campus, Fern Barrow}, 
            city={Poole},
            citysep={}, % Uncomment if no comma needed between city and postcode
            postcode={BH12 5BB}, 
            state={Dorset},
            country={UK}}

% Corresponding author text
\cortext[1]{Corresponding author}

% Footnote text
\fntext[1]{Department of Engineering}
\fntext[2]{National Centre for Computer Animation}

% For a title note without a number/mark
%\nonumnote{}

% Here goes the abstract
\begin{abstract}
  We evaluate multiple machine learning model configurations for predicting specific capacitance, showing that incorporating an area-based loss consistently improves accuracy and stability across runs. The best-performing model achieves an average error of 3.75\%, compared with a baseline error of 15.49\%. Analysis of the model's learned weights indicates that electrolyte temperature is the dominant factor influencing specific capacitance, followed closely by active mass and electrolysis voltage.
\end{abstract}

% Use if graphical abstract is present
%\begin{graphicalabstract}
%\includegraphics{}
%\end{graphicalabstract}

\begin{highlights}
\item 
\item 
\item 
\end{highlights}

% Keywords
% Each keyword is seperated by \sep
\begin{keywords}
 \sep \sep \sep
\end{keywords}

\maketitle

\section{Deep learning analysis}
\label{sec:ml_analysis}
Machine learning models can be thought of as universal function approximators. That is, provided enough data to learn from, they are able to model any continuous, closed domain function to an arbitrary degree of accuracy~\citep{geuchenUniversalApproximationComplexvalued2025}. Such models consist of interconnected ``neurons'' arranged in layers. These connections are dense, meaning each neuron is connected to all other neurons in the previous and next layer, giving rise to the common ``fully connected'' layer terminology. We will refer to a single layer as $F_{i}^{n,m}$ where $i$ is the position of the layer, $n$ is the input size (the number of input neurons expected), and $m$ is the output size. The layer computes:

\begin{equation}
\hat{y} = F_{i}^{n, m}(x) = W_{i}x + b_{i}
\end{equation}


where $x$ is an n-dimensional vector, $\hat{y}$ is an m-dimensional vector, $W_i$ is an $n \times m$ weight matrix and $b_i$ is a constant term.  Layers may be chained sequentially, as long as the inner dimensions of adjacent layers are equal, i.e. $W_i$ and $W_{i+1}$ can be multiplied. Such a sequence of connected layers is commonly referred to as a Multilayer Perceptron (MLP). An important element of the layers of the MLP is the activation function, which is applied to the output of each neuron, and introduces non-linearity into the model. This is essential for an MLP to fit the definition of a universal function approximator as defined earlier, because any sequence of fully connected layers must necessarily collapse into a single linear transform, which is not powerful enough to represent more complicated functions. The Rectified Linear Unit function (ReLU) is a popular activation function~\citep{agarapDeepLearningUsing2019} designed for this purpose and is defined as follows:

\begin{equation}
\text{ReLU}(x) = \begin{cases}
  0 & x \leq 0 \\
  x & x > 0
\end{cases}
\end{equation}

Thus, the MLP must have a ReLU activation function between each hidden layer, giving the final model structure as laid out in Figure~\ref{fig:model_arch}. Obtaining a $\hat{y}$ prediction from an MLP completes the ``forward pass'' part of training. The prediction is then evaluated against the target value $y$ (also called the ground truth value) using a cost function $L$ -- see Equations~\ref{eq:loss_current}~-~\ref{eq:loss} for how it is defined for this application. The partial derivative of $L$ is calculated with respect to each parameter $w_{i}^{n,m}$ in $W_i$: 

\begin{figure*}
 \centering
 \includegraphics[width=\linewidth]{model_arch.png}
 \caption{An overview of the training pipeline and model architecture, incorporating dropout after the largest layer to discourage overfitting. The input is a 6-dimensional vector consisting of a potential step, scan direction, and several experimental conditions under which the electrode material was sysnthesised; the output is a prediction of the current value at that potential. Four trainable weights $W^{4}$ provide a scaling factor for each of the conditions. Ground truth hysteresis curves shown in blue and model prediction shown in orange.}
 \label{fig:model_arch}
\end{figure*}

\begin{equation}
\frac{\partial L}{\partial w_{i}^{n,m}} = \frac{\partial L }{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial w_{i}^{n,m}}
\end{equation}

Computing all such partials completes the ``backwards'' pass of the training step -- a process known as backpropagation --  and gives us $\frac{\partial L}{\partial W_i}$, which tells the model how much, and the direction in which $W$ should change in order to minimise $L$. Repeating these forward and backwards passes over the MLP over and over again brings the weights closer to their ``ideal'' values -- ones for which $L$ is minimised. In other words, the optimsing algorithm uses the difference between the output of the model and its target to update $W$ in the correct direction. This is what is meant by training a machine learning model.  

\subsection{Previous work}
The application of machine learning systems to the prediction of specific capacitance values is varied -- some previous investigations involve predicting specific capacitance directly from experimental conditions~\citep{kumaryogeshMachineLearningApproach2025}, while others use these experimental conditions to predict hysteresis curves~\citep{ravichandranMachineLearningBasedPrediction2024}; the latter approach allows the indirect calculation of specific capacitance $C_{sp}$, which is proportional to the area between charge and discharge curves. It is this latter approach that is used by the present study, because predicting the full charge-discharge dynamics of cyclic voltammetry allows the model to generalise better to a wider range of conditions~\citep{deebansokCapacitiveTendencyConcept2024} -- especially important given the limited data available for this study. Using this approach, $C_{sp}$ is given by:

\begin{equation}
  \label{eq:specific_cap}
  C_{sp} = \frac{\int I_{pred}(E) \,dE}{ 2 \cdot \nu \cdot m \cdot \Delta V}
\end{equation}


where $I_{pred}$ is the function that is approximated by the MLP, $E$ is the potential, $\nu$ is the scanrate, m is the total mass of the active material in the electrodes, and $\Delta V$ is the change in voltage over the whole charge/discharge cycle.

\subsection{Dataset}
The complete dataset is made up of current samples from 5 cyclic voltammetry cycles -- see Table~\ref{tab:dataset}. These were collected via potentiostat with a scanrate of \SI{100}{\milli\volt\per\second}. Each cycle consists of 264 rows, with columns for current (I / \unit{\ampere}), voltage step (E / \unit{\volt}), active electrode mass (M / \unit{\milli\gram}), temperature (T / \unit{\degreeCelsius}), electrolysis duration (D / \unit{\hour}), electrolysis voltage ($V_e$ / \unit{\volt}), and scan direction (S). The last feature tells the model if the particular point is on the charge or discharge curve and is represented by either +1 (charging)  or -1 (discharging).  

\begin{table}
\caption{Characteristics of each cycle that constitutes the dataset used for training our model. The scanrate was \SI{100}{\milli\volt\per\second} in all cases.}
\label{tab:dataset}
\small
\centering
\begin{tblr}{
  hline{1-2} = {-}{}
}
Cycle      & M / mg  & T / $^{\circ}$C& D / h & $V_e$ / V & Electrolyte \\
BCMS2      & 0.11    & 800            & 2     & 2         & Ethaline    \\
BCMS3      & 0.11    & 750            & 2     & 2         & Ethaline    \\
BCMS5      & 0.18    & 650            & 2     & 2         & Ethaline    \\
BCMS7      & 0.25    & 700            & 2     & 2.8       & Ethaline    \\
BCMS9      & 0.25    & 750            & 2     & 2.8       & Ethaline       
\end{tblr}
\end{table}

Notice that the various inputs span many orders of magnitude -- this is a problem for machine learning models. Using raw features such as those presented in Table~\ref{tab:dataset} mean that ones with large absolute values dominate the weights of the model, even though they may not be as important, and vice versa, which can lead to lower performance~\citep{kimInvestigatingImpactData2025}. For this reason, all features are scaled across all cycles such that they have zero mean and unit standard deviation. To transform an individual instance of a feature $d_i$ (e.g. electrode mass, temperature) to its scaled value $d_{norm,i}$:

\begin{equation}\label{eq:norm}
  d_{norm,i} = \frac{d_i - \mu(D)}{\sigma(D)}
\end{equation}

where $D$ is the collection of all the values for this feature, $\mu$ is the mean of values in $D$, and $\sigma$ is their standard deviation. These scaled values are used in all subsequent machine learning operations, and final outputs are de-normalised using the inverse of Equation~\ref{eq:norm} for display and comparison with experimental values. Current values were also transformed in this way. However, the potential step $E$ was rescaled slightly differently: rather than ensuring zero mean and unit variance, we rescale them such that the minimum potential across the whole dataset is -1 and the maximum is +1:

\begin{align}
  E_{mid} &= \frac{E_{max} + E_{min}}{2} \nonumber \\
  E_{half-range} &= \frac{E_{max} - E_{min}}{2} \nonumber \\
  E_{norm} &= \frac{E - E_{mid}}{E_{half-range}}
\end{align}

where $E_{min}$ and $E_{max}$ are the minimum and maximum potential values \emph{across the whole dataset}. This scaling ensures that all cycles share a common and bounded potential domain, making it easier for the model to lear consistent relationships across different experimental conditions.

The input to the model is therefore a 6 dimensional, normalised feature vector that consists of a potential step and experimental conditions under which the electrode material was synthesised, and the output is the current value at the potential step.  

\subsection{Experimental design and model architecture}
\label{subsec:arch}
We employ leave-one-out cross validation when training: for any one run, the model is trained only on points from 4 of the cycles; points from the 5$^{th}$ are held out for validation. Here, validation means only evaluating the forward pass of the model and not updating the weights of the model. It is a test to determine if the model is able to generalise to ``unseen'' data, and each cycle is subjected to this treatment in turn. We repeat training runs five times independently to build confidence that the model's output is reliable.

Due to the small size of the dataset, we introduce a simple heuristic to improve the training stability and to encourage the model to learn meaningful relationships between experimental conditions and the voltammetric response. This is realised by introducing four trainable parameters that act as scaling factors for the experimental conditions that are used when synthesising the black carbon -- active mass (M), electrolysis temperature (T), electrolysis duration (D) and electrolysis voltage ($V_e$). These parameters allow the model to explicitly learn the relative importance of each condition rather than solely relying on implicit weighting within the first layer of the MLP. 

As illustrated in Figure~\ref{fig:model_arch}, the learned scaling parameters are applied to the condition vector prior to concatenation with the potential step (E) and scan direction (S), resulting in the 6-dimensional input that is expected by the MLP. Scaling is applied in the following way: the learned weights are first divided by a temperature parameter $\tau$, which controls the sharpness of the relative weighting, and subsequently normalised by the softmax function to give the scaling factor $s_i$ for each learned weight:

\begin{equation}
  \label{eq:softmax}
  s_i = \frac{\exp(\alpha_i / \tau)}{\sum_{j=1}^{4} \exp(\alpha_j / \tau)}
\end{equation}

where $\alpha_i$ is any one of the four learned weights. The resulting normalised weights are multiplied element-wise by the condition vector, yielding the weighted condition vector.

The rest of the model is a multilayered perceptron with 4 hidden layers in between a 6-neuron input layer and a 1-neuron output layer. Please refer to Figure~\ref{fig:model_arch} for the full model architecture. Note the dropout layer, which randomly (with some probability $p$) deactivates a subset of neurons during training. This is done so that the model does not rely too heavily on any single neuron or set of neurons, thereby reducing overfitting and improving generalisation to new data~\citep{mouDropoutTrainingDatadependent2018}. Wider layers with more neurons benefit more from dropout as they are more at risk from overfitting~\citep{srivastavaDropoutSimpleWay2014}, hence the placement between $F_{2}$ and $F_{3}$.

As mentioned in the Section~\ref{sec:ml_analysis}, the objective function scores the output of the MLP so it can be used in gradient calculations, which in turn are used to inform updates to the model's weights. Because the model predicts the current at a particular voltage step, part of the loss function is the mean squared error (MSE) between the predicted and actual value. This is given by:

\begin{figure*}
 \centering
 \includegraphics[width=\linewidth]{results.png}
 \caption{A plot reporting the average normalised $C_{sp}$ over 5 runs per cycle per experimental setting. Error bars indicate 95\% confidence intervals over runs.}
 \label{fig:results}
\end{figure*}

\begin{equation}
  \label{eq:loss_current}
  L_{curr} = \frac{1}{N} \sum_{i=1}^{N} (\hat{y}_i - y_i)^{2}
\end{equation}

where $\hat{y}_i$ is the predicted current value, $y_i$ is the true value, and $N$ is the number of predicted points. Further, in order to maintain a smooth curve that is physically consistent with the behaviour of real hysteresis curves, we impose a penalty on the second derivative of the predicted current with respect to potential, discouraging sharp local curvature and jitter:

\begin{equation}
  \label{eq:loss_smooth}
  L_{smth} =  \Bigl\lVert\frac{\partial^2 I_{pred}}{\partial E^2}\Bigr\rVert_{2}^{2}
\end{equation}

where $I_{pred}$ is the predicted current and $E$ is the potential. Finally, we also use the area of the predicted curve in another MSE loss calculation to encourage the model to produce the correct net area exhibited by the experimental curve:

\begin{equation}
  \label{eq:loss_area}
  L_{area} = \frac{1}{M} \sum_{j=1}^{M} (\hat{a}_j - a_j)^{2}
\end{equation}
where $M$ is the number of cycles, $a_j$ is the actual area between the curves for a given cycle, and $\hat{a}_j$ is the area calculated using predicted current values.  The losses are combined for final  objective for the MLP:
\begin{equation}
  \label{eq:loss}
  L = L_{curr} + L_{smth} + L_{area}
\end{equation}


In order to assess the importance of these loss functions (as well as other  model settings), an ablation study was conducted to measure the impact these settings on the final prediction. A comparison of $C_{sp}$ predicted by models under these experimental settings is given in Figure~\ref{fig:results}, and a comparison of their relative errors is given in Table~\ref{tab:errors}. The base MLP, henceforth called ``Base'' is only tasked with the $L_{curr}$ objective. The following experimental modifications were added to the Base model:
\begin{enumerate}
  \item  ``+ D'' -- inclusion of a \textbf{D}ropout layer, as discussed in Section~\ref{subsec:arch}
  \item  ``+ S'' -- addition of the \textbf{S}moothing $L_{smth}$ objective to $L$
  \item  ``+ A'' -- addition of the \textbf{A}rea $L_{area}$ objective to $L$ 
  \item  ``+ W'' -- inclusion of trainable \textbf{W}eights for each of the synthesis conditions 
\end{enumerate}


\subsection{Results and discussion}


\begin{table}
\caption{Average error (relative \%) for each cycle in leave-one-out cross validation over 5 independent runs. Base+D+A exhibits the least overall error across all the settings.}
\label{tab:errors}
\small
\centering
\begin{tblr}{
  hline{1-2,7,8,9} = {-}{},
  colsep = 4pt
}
Cycle   & Base    & {Base\\+D}  & {Base\\+D\\+S}  & {Base\\+D\\+S\\+A}   & {Base\\+D\\+A} & {Base\\+D\\+A\\+W}\\
BCMS2   & 0.62    & 0.58        & 2.54            & 7.17                 & 0.77           & 1.22              \\
BCMS3   & 29.82   & 23.28       & 20.15           & 16.11                & 16.93          & 1.53              \\
BCMS5   & 7.04    & 15.05       & 7.88            & 2.61                 & 8.83           & 1.77              \\
BCMS7   & 30.87   & 25.37       & 18.50           & 26.78                & 17.92          & 7.42              \\
BCMS9   & 9.12    & 4.64        & 1.91            & 2.42                 & 0.39           & 6.83              \\
Average & 15.49   & 13.79       & 10.20           & 11.02                & 8.97           & \textbf{3.75}
\end{tblr}
\end{table}

Results were collected for each experimental setting described in Section~\ref{subsec:arch}. Figure~\ref{fig:results} reports the averaged, normalised $C_{sp}$ values computed over five independent runs. Predicted $C_{sp}$ were normalised by their corresponding ground-truth values to facilitate comparison across settings, as $C_{sp}$ spans several orders of magnitude. Error bars indicate the 95\% confidence interval over the five runs. 

Overall, the Base+D+A+W configuration (corresponding to the model incorporating dropout, condition scaling, and the area loss of Equation~\ref{eq:loss_area}) exhibits the samllest deviation from the $C_{sp}$ baseline, on average.  This setting also yields comparatively narrower confidence intervals, suggesting improved stability across runs. Incorporating the area-based loss term resulted in improved performance across all curves. As shown in Figure~\ref{fig:results}, models that include this loss term tend to produce predictions that are closer to the target baseline. It should be noted that the smoothness loss term (Equation~\ref{eq:loss_smooth}) seems to be somewhat at odds with the area loss. This effect is reflected in  Table~\ref{tab:errors}, which presents the relative error percentage between the predicted and true $C_{sp}$ values across all the experimental settings. The addition of area loss to Base+D+S (10.2\% error) results in the error increasing slightly to 11.02\%. Removing the smoothness loss (corresponding to the Base+D+A configuration) yields a lower overall error (8.97\%). This suggests that the two loss terms may impose competing constraints on the learned representations, which could partially limit their combined effectiveness. However, the most effective strategy incorporates condition scaling to the latter configuration (giving Base+D+A+W), and yielding an average error of 3.75\%.

\begin{table}
\caption{Relative weights assigned by the proposed model to the various molten salt parameters. The exclusion of one curve from the training gives a slightly different set of weights for each experiment, but overall, the model was most sensitive to temperature (T), electrolysis voltage ($V_e$) and active mass (M). Electrolysis duration (D) was found to be the least important input in predicting $C_{sp}$.}
\label{tab:cond_weights}
\centering
\begin{tblr}{
  hline{1,2,7,8} = {-}{},
}
Experiment & M     & T     & D     & $V_e$ \\
BCMS2      & 0.193 & 0.294 & 0.173 & 0.339 \\
BCMS3      & 0.266 & 0.264 & 0.237 & 0.233 \\
BCMS5      & 0.254 & 0.285 & 0.175 & 0.286 \\
BCMS7      & 0.223 & 0.301 & 0.202 & 0.275 \\
BCMS9      & 0.214 & 0.413 & 0.170 & 0.203 \\ 
Average    & 0.230 & 0.311 & 0.191 & 0.267 \\
\end{tblr}
\end{table}

The inclusion of trainable scaling values for the four experimental conditions (M, T, V and D) offers insights into the relative importance of each of these in determining $C_{sp}$. Table~\ref{tab:cond_weights} demonstrates that on average, the model assigns most importance (31.1\% relative weight) to the temperature of the molten salt (T). This is followed by electrolysis voltage ($V_e$) at 26.7\%, and active material mass (M) at 23.0\%. Finally, duration of electrolysis (D) recieves the lowest relative weight (19.1\%). This is unsurprising, as this setting did not vary at all  across the dataset (see Table~\ref{tab:dataset}), so could not explain any of the variance in the predicted output.

A key limitation of the experimental setup lies in the limited diversity of the input features. Although each of the five cycles contains 264 samples, all samples within a given cycle share the same experimental conditions; the only varying factor is the voltage step. Moreover, the voltage progression itself is identical across all cycles. Thus, even though a unique feature vector exists for each point, the dataset comprises only 5 unique condition vectors across 1320 samples. This extremely low condition variance substantially constrains the expressive capacity available to the model and limits the generalisability of the learned representations. In this context, the fact that the model exhibits meaningful performance at all is somewhat surprising, and underscores the need for more diverse experimental conditions (i.e., a wider range of these conditions) in future studies.

\section{Conclusion}
The conclusions section should come in this section at the end of the article, before the Author contributions statement and/or Conflicts of interest statement.


%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections
%% \appendix


% To print the credit authorship contribution details
% \printcredits

%% Loading bibliography style file
% \bibliographystyle{model1-num-names}
\bibliographystyle{cas-model2-names}
% Loading bibliography database
\bibliography{refs}

% Biography
%\bio{}
% Here goes the biography details.
%\endbio

%\bio{pic1}
% Here goes the biography details.
%\endbio

\end{document}

